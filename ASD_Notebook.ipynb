{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c60ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in ./.venv/lib/python3.9/site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./.venv/lib/python3.9/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.venv/lib/python3.9/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.9/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.venv/lib/python3.9/site-packages (from librosa) (0.13.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./.venv/lib/python3.9/site-packages (from librosa) (4.15.0)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Using cached msgpack-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Using cached llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.9/site-packages (from pooch>=1.1->librosa) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "Using cached numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "Using cached llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soxr-1.0.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy_loader, audioread, pooch, numba, librosa\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [librosa]m7/8\u001b[0m [librosa]d]r]\n",
      "\u001b[1A\u001b[2KSuccessfully installed audioread-3.0.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.43.0 msgpack-1.1.1 numba-0.60.0 pooch-1.8.2 soxr-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dd55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.9/site-packages (2.8.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.9/site-packages (4.56.2)\n",
      "Collecting peft\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.9/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.9/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.9/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.9/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.9/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.9/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./.venv/lib/python3.9/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.9/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./.venv/lib/python3.9/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.9/site-packages (from triton==3.4.0->torch) (53.0.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.9/site-packages (from triton==3.4.0->torch) (8.7.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.9/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.9/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.9/site-packages (from peft) (7.1.0)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading pandas-2.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas, accelerate, peft\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [peft][32m4/5\u001b[0m [peft]erate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.10.1 pandas-2.3.2 peft-0.17.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib numpy torch torchaudio pandas transformers peft scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ff66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce1593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simplified EAT + KMeans anomaly detection pipeline focusing on performance\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys, math, json, argparse, time, re, random\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "# Headless plotting\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "    PEFT_AVAILABLE = True\n",
    "except Exception:\n",
    "    PEFT_AVAILABLE = False\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, roc_curve, auc, precision_recall_curve, \n",
    "    f1_score, confusion_matrix, accuracy_score\n",
    ")\n",
    "\n",
    "# Load modules from existing script\n",
    "sys.path.insert(0, '/home/sey87151/EAT_Clean')\n",
    "from v3_reporter import EATFeatureExtractor\n",
    "\n",
    "# LoRa defaults\n",
    "DEFAULT_LORA_R = 32\n",
    "DEFAULT_LORA_ALPHA = 64\n",
    "DEFAULT_LORA_DROPOUT = 0.05\n",
    "DEFAULT_FT_LR = 1e-4\n",
    "DEFAULT_FT_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f77db26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_label_from_path(p):\n",
    "    \"\"\"Infer label from path: 0=normal, 1=anomaly\"\"\"\n",
    "    p_str = str(p).lower()\n",
    "    if \"anomaly\" in p_str or \"abnormal\" in p_str:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def infer_domain_from_path(p):\n",
    "    \"\"\"Infer domain from path\"\"\"\n",
    "    return Path(p).parent.name\n",
    "\n",
    "def chunked(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def collect_domain_paths(root_dir, machine):\n",
    "    \"\"\"Collect train and test paths for a machine based on folder structure.\"\"\"\n",
    "    machine_dir = Path(root_dir) / machine\n",
    "    if not machine_dir.exists():\n",
    "        print(f\"Machine directory not found: {machine_dir}\")\n",
    "        return [], []\n",
    "    \n",
    "    train_dir = machine_dir / \"train\"\n",
    "    test_dir = machine_dir / \"test\"\n",
    "    \n",
    "    if not train_dir.exists() or not test_dir.exists():\n",
    "        print(f\"Train or test directory not found in: {machine_dir}\")\n",
    "        return [], []\n",
    "    \n",
    "    # Collect training paths (all from train folder - should be normal)\n",
    "    train_paths = list(train_dir.glob(\"*.wav\"))\n",
    "    \n",
    "    # Collect test paths (all from test folder - mix of normal and anomaly)\n",
    "    test_paths = list(test_dir.glob(\"*.wav\"))\n",
    "    \n",
    "    print(f\"Found {len(train_paths)} training files\")\n",
    "    print(f\"Found {len(test_paths)} test files\")\n",
    "    \n",
    "    return train_paths, test_paths\n",
    "\n",
    "# ----------------- LoRA utilities (simplified copy) -----------------\n",
    "ATTN_TOKENS = [\n",
    "    \"qkv\", \"proj\",\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"out_proj\",\n",
    "    \"query\", \"key\", \"value\", \"in_proj\", \"in_proj_weight\", \"in_proj_bias\",\n",
    "]\n",
    "\n",
    "def present_attention_tokens(model: nn.Module) -> List[str]:\n",
    "    names = [n for n, _ in model.named_modules()]\n",
    "    present = [tok for tok in ATTN_TOKENS if any(tok in n for n in names)]\n",
    "    return sorted(set(present), key=present.index)\n",
    "\n",
    "def resolve_lora_targets(model: nn.Module, override: Optional[str]) -> List[str]:\n",
    "    names = [n for n, _ in model.named_modules()]\n",
    "    if override:\n",
    "        raw = [t.strip() for t in override.split(',') if t.strip()]\n",
    "        filtered = [t for t in raw if any(t in n for n in names)]\n",
    "        if filtered:\n",
    "            return sorted(set(filtered), key=filtered.index)\n",
    "        print(f\"[LoRA][WARN] None of --lora_targets matched actual module names: {raw}\")\n",
    "    present = present_attention_tokens(model)\n",
    "    if present:\n",
    "        return present\n",
    "    fallback = [\"qkv\", \"q_proj\", \"k_proj\", \"v_proj\"]\n",
    "    fb_filtered = [t for t in fallback if any(t in n for n in names)]\n",
    "    if fb_filtered:\n",
    "        return fb_filtered\n",
    "    raise ValueError(\"Could not auto-discover LoRA targets; pass --lora_targets explicitly.\")\n",
    "\n",
    "def find_lora_target_names(model: nn.Module, tokens: List[str], last_n: int,\n",
    "                           include_only_attn: bool = True, include_mlp_fc1: bool = False) -> List[str]:\n",
    "    block_ids = []\n",
    "    for n, _ in model.named_modules():\n",
    "        m = re.match(r\"^model\\.blocks\\.(\\d+)\\.\", n)\n",
    "        if m:\n",
    "            block_ids.append(int(m.group(1)))\n",
    "    if not block_ids:\n",
    "        return []\n",
    "    cutoff = max(0, max(block_ids) - last_n + 1)\n",
    "    selected: List[str] = []\n",
    "    for name, module in model.named_modules():\n",
    "        if not isinstance(module, nn.Linear):\n",
    "            continue\n",
    "        m = re.match(r\"^model\\.blocks\\.(\\d+)\\.\", name)\n",
    "        if not m:\n",
    "            continue\n",
    "        blk = int(m.group(1))\n",
    "        if blk < cutoff:\n",
    "            continue\n",
    "        if include_only_attn and \".attn.\" not in name:\n",
    "            if include_mlp_fc1 and name.endswith(\".mlp.fc1\"):\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "        if not any(tok in name for tok in tokens):\n",
    "            continue\n",
    "        selected.append(name)\n",
    "    out=[]; seen=set()\n",
    "    for n in selected:\n",
    "        if n not in seen:\n",
    "            out.append(n); seen.add(n)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af5300",
   "metadata": {},
   "source": [
    "# Dataset Management and Utility Functions\n",
    "\n",
    "This section contains utility functions for:\n",
    "- Path management and label inference\n",
    "- Data collection from machine directories\n",
    "- General helper functions for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de15df2",
   "metadata": {},
   "source": [
    "# LoRA (Low-Rank Adaptation) Utilities\n",
    "\n",
    "This section implements utilities for LoRA fine-tuning:\n",
    "- Attention module detection\n",
    "- Target module resolution\n",
    "- LoRA configuration helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96fc1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA attention tokens and utility functions\n",
    "ATTN_TOKENS = [\n",
    "    \"qkv\", \"proj\",\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"out_proj\",\n",
    "    \"query\", \"key\", \"value\", \"in_proj\", \"in_proj_weight\", \"in_proj_bias\",\n",
    "]\n",
    "\n",
    "def present_attention_tokens(model: nn.Module) -> List[str]:\n",
    "    names = [n for n, _ in model.named_modules()]\n",
    "    present = [tok for tok in ATTN_TOKENS if any(tok in n for n in names)]\n",
    "    return sorted(set(present), key=present.index)\n",
    "\n",
    "def resolve_lora_targets(model: nn.Module, override: Optional[str]) -> List[str]:\n",
    "    names = [n for n, _ in model.named_modules()]\n",
    "    if override:\n",
    "        raw = [t.strip() for t in override.split(',') if t.strip()]\n",
    "        filtered = [t for t in raw if any(t in n for n in names)]\n",
    "        if filtered:\n",
    "            return sorted(set(filtered), key=filtered.index)\n",
    "        print(f\"[LoRA][WARN] None of --lora_targets matched actual module names: {raw}\")\n",
    "    present = present_attention_tokens(model)\n",
    "    if present:\n",
    "        return present\n",
    "    fallback = [\"qkv\", \"q_proj\", \"k_proj\", \"v_proj\"]\n",
    "    fb_filtered = [t for t in fallback if any(t in n for n in names)]\n",
    "    if fb_filtered:\n",
    "        return fb_filtered\n",
    "    raise ValueError(\"Could not auto-discover LoRA targets; pass --lora_targets explicitly.\")\n",
    "\n",
    "def find_lora_target_names(model: nn.Module, tokens: List[str], last_n: int,\n",
    "                           include_only_attn: bool = True, include_mlp_fc1: bool = False) -> List[str]:\n",
    "    block_ids = []\n",
    "    for n, _ in model.named_modules():\n",
    "        m = re.match(r\"^model\\.blocks\\.(\\d+)\\.\", n)\n",
    "        if m:\n",
    "            block_ids.append(int(m.group(1)))\n",
    "    if not block_ids:\n",
    "        return []\n",
    "    cutoff = max(0, max(block_ids) - last_n + 1)\n",
    "    selected: List[str] = []\n",
    "    for name, module in model.named_modules():\n",
    "        if not isinstance(module, nn.Linear):\n",
    "            continue\n",
    "        m = re.match(r\"^model\\.blocks\\.(\\d+)\\.\", name)\n",
    "        if not m:\n",
    "            continue\n",
    "        blk = int(m.group(1))\n",
    "        if blk < cutoff:\n",
    "            continue\n",
    "        if include_only_attn and \".attn.\" not in name:\n",
    "            if include_mlp_fc1 and name.endswith(\".mlp.fc1\"):\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "        if not any(tok in name for tok in tokens):\n",
    "            continue\n",
    "        selected.append(name)\n",
    "    out=[]; seen=set()\n",
    "    for n in selected:\n",
    "        if n not in seen:\n",
    "            out.append(n); seen.add(n)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff147493",
   "metadata": {},
   "source": [
    "# Dataset and Neural Network Components\n",
    "\n",
    "This section includes:\n",
    "- Custom dataset class for pseudo-labeled data\n",
    "- Neural network heads (Linear and CosFace)\n",
    "- Data collation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419085e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, wavs: List[np.ndarray], labels: np.ndarray, sr: int, target_len: Optional[int]):\n",
    "        assert len(wavs) == len(labels)\n",
    "        self.wavs = wavs\n",
    "        self.labels = labels.astype(np.int64)\n",
    "        self.sr = sr\n",
    "        self.target_len = target_len\n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "    def __getitem__(self, idx: int):\n",
    "        w = self.wavs[idx]; y = int(self.labels[idx])\n",
    "        w_t = torch.tensor(w, dtype=torch.float32)\n",
    "        if w_t.ndim!=1:\n",
    "            w_t = w_t.view(-1)\n",
    "        w_t = w_t - w_t.mean()\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            w_t.unsqueeze(0), htk_compat=True, sample_frequency=self.sr,\n",
    "            use_energy=False, window_type=\"hanning\", num_mel_bins=128,\n",
    "            dither=0.0, frame_shift=10,\n",
    "        )\n",
    "        T_true = fb.size(0)\n",
    "        if self.target_len is not None:\n",
    "            if T_true < self.target_len:\n",
    "                fb = F.pad(fb, (0,0,0,self.target_len - T_true))\n",
    "            elif T_true > self.target_len:\n",
    "                fb = fb[: self.target_len, :]\n",
    "        fb = (fb + 4.288) / 4.469\n",
    "        L = min(T_true, self.target_len or T_true)\n",
    "        return fb.unsqueeze(0), y, L\n",
    "\n",
    "def collate_fb(items):\n",
    "    fbs, ys, lens = zip(*items)\n",
    "    x = torch.stack(fbs, dim=0)\n",
    "    y = torch.tensor(ys, dtype=torch.long)\n",
    "    lengths = torch.tensor(lens, dtype=torch.long)\n",
    "    return x, y, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee496a3b",
   "metadata": {},
   "source": [
    "# Neural Network Heads and K-means Optimization\n",
    "\n",
    "Implementation of different neural network heads and clustering optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9f8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearHead(nn.Module):\n",
    "    def __init__(self, in_dim: int, n_classes: int):\n",
    "        super().__init__(); self.fc = nn.Linear(in_dim, n_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "class CosFaceHead(nn.Module):\n",
    "    def __init__(self, in_dim: int, n_classes: int, s: float = 64.0, m: float = 0.35):\n",
    "        super().__init__()\n",
    "        # W has shape [in_dim, n_classes]; columns are class weight vectors\n",
    "        self.W = nn.Parameter(torch.randn(in_dim, n_classes))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        self.s = float(s)\n",
    "        self.m = float(m)\n",
    "    def forward(self, x, y):\n",
    "        # L2-normalize features and class weights\n",
    "        x_n = F.normalize(x, dim=1)\n",
    "        W_n = F.normalize(self.W, dim=0)  # normalize columns (each class vector)\n",
    "        # Cosine logits\n",
    "        logits = x_n @ W_n  # [B, C]\n",
    "        # Subtract margin from the target class cosine\n",
    "        # (equivalent to logits.scatter_ with gathered target)\n",
    "        onehot = F.one_hot(y, num_classes=logits.size(1)).float()\n",
    "        logits_m = logits - self.m * onehot\n",
    "        # Scale by s\n",
    "        return self.s * logits_m\n",
    "\n",
    "def auto_choose_k(feats: np.ndarray, k_grid: List[int] = None, seed: int = 42) -> int:\n",
    "    if k_grid is None: k_grid = [12,18,24,32]\n",
    "    optimal_k = k_grid[0]; best=-1.0\n",
    "    X = StandardScaler().fit_transform(feats)\n",
    "    for k in k_grid:\n",
    "        try:\n",
    "            km = KMeans(n_clusters=k, n_init=\"auto\", random_state=seed)\n",
    "            labels = km.fit_predict(X)\n",
    "            if len(set(labels))==1: continue\n",
    "            sil = silhouette_score(X, labels)\n",
    "        except Exception:\n",
    "            sil=-1.0\n",
    "        if sil>best: best=sil; optimal_k=k\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bd393",
   "metadata": {},
   "source": [
    "# Configuration and Parameters Setup\n",
    "\n",
    "Set up experiment parameters and configure the anomaly detection pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93509b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simplified EAT Anomaly Detection for bearing ===\n",
      "Model: worstchan/EAT-base_epoch30_pretrain\n",
      "Batch size: 32\n",
      "Target length: 1024\n",
      "Sample rate: 16000\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters for the experiment\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.dataset_root = \"./dataset\"\n",
    "        self.machine = \"bearing\"\n",
    "        self.model_id = \"worstchan/EAT-base_epoch30_pretrain\"\n",
    "        self.sr = 16000\n",
    "        self.target_length = 1024\n",
    "        self.batch_size = 32\n",
    "        self.max_train = 10000\n",
    "        self.seed = 42\n",
    "        self.pool_mode = \"mean_with_cls\"\n",
    "        self.use_l2_norm = False\n",
    "        \n",
    "        # LoRa fine-tuning parameters\n",
    "        self.do_lora_ft = True\n",
    "        self.auto_hparam = False\n",
    "        self.lora_r = DEFAULT_LORA_R\n",
    "        self.lora_alpha = DEFAULT_LORA_ALPHA\n",
    "        self.lora_dropout = DEFAULT_LORA_DROPOUT\n",
    "        self.lora_targets = None\n",
    "        self.lora_last_n = 4\n",
    "        self.lora_include_mlp_fc1 = False\n",
    "        self.ft_lr = DEFAULT_FT_LR\n",
    "        self.ft_epochs = DEFAULT_FT_EPOCHS\n",
    "        self.grad_clip = 1.0\n",
    "        self.ft_warmup = 0.05\n",
    "        self.ft_val_split = 0.1\n",
    "        self.early_stop_patience = 10\n",
    "        self.use_cosface = False\n",
    "        \n",
    "        # CosFace hyperparameters\n",
    "        self.cosface_s = 64.0\n",
    "        self.cosface_m = 0.35\n",
    "        \n",
    "        # Embedding compactness & margin enhancements\n",
    "        self.add_center_loss = False\n",
    "        self.center_ema = 0.9\n",
    "        self.lambda_center = 0.1\n",
    "        self.add_supcon = False\n",
    "        self.supcon_temp = 0.07\n",
    "        self.lambda_supcon = 0.1\n",
    "\n",
    "# Initialize configuration\n",
    "args = Config()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "print(f\"=== Simplified EAT Anomaly Detection for {args.machine} ===\")\n",
    "print(f\"Model: {args.model_id}\")\n",
    "print(f\"Batch size: {args.batch_size}\")\n",
    "print(f\"Target length: {args.target_length}\")\n",
    "print(f\"Sample rate: {args.sr}\")\n",
    "print(f\"Random seed: {args.seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e3d7c5",
   "metadata": {},
   "source": [
    "# Data Collection and Loading\n",
    "\n",
    "Collect training and testing data from the dataset directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cf875da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1100 training files\n",
      "Found 200 test files\n",
      "Training on 1100 normal samples\n",
      "Testing on 200 samples (100 normal + 100 anomalous)\n",
      "\n",
      "Sample training paths:\n",
      "  1. dataset/bearing/train/section_00_source_train_normal_0364_noAttribute.wav\n",
      "  2. dataset/bearing/train/section_00_source_train_normal_0643_noAttribute.wav\n",
      "  3. dataset/bearing/train/section_00_source_train_normal_0188_noAttribute.wav\n",
      "\n",
      "Sample test paths:\n",
      "  1. dataset/bearing/test/section_00_target_test_normal_0020_noAttribute.wav -> normal\n",
      "  2. dataset/bearing/test/section_00_target_test_anomaly_0031_noAttribute.wav -> anomaly\n",
      "  3. dataset/bearing/test/section_00_source_test_anomaly_0043_noAttribute.wav -> anomaly\n"
     ]
    }
   ],
   "source": [
    "# 1) Collect data from train and test folders\n",
    "train_paths, test_paths = collect_domain_paths(args.dataset_root, args.machine)\n",
    "\n",
    "if len(train_paths) == 0 or len(test_paths) == 0:\n",
    "    print(\"Insufficient data for training/testing.\")\n",
    "    print(f\"Found {len(train_paths)} training files and {len(test_paths)} test files\")\n",
    "else:\n",
    "    # Create labels for test data based on filenames\n",
    "    test_labels = []\n",
    "    for path in test_paths:\n",
    "        test_labels.append(infer_label_from_path(path))\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    # Count normal and anomaly in test set\n",
    "    n_test_normal = np.sum(test_labels == 0)\n",
    "    n_test_anomaly = np.sum(test_labels == 1)\n",
    "\n",
    "    print(f\"Training on {len(train_paths)} normal samples\")\n",
    "    print(f\"Testing on {len(test_paths)} samples ({n_test_normal} normal + {n_test_anomaly} anomalous)\")\n",
    "    \n",
    "    # Display sample paths\n",
    "    print(f\"\\nSample training paths:\")\n",
    "    for i, path in enumerate(train_paths[:3]):\n",
    "        print(f\"  {i+1}. {path}\")\n",
    "    \n",
    "    print(f\"\\nSample test paths:\")\n",
    "    for i, path in enumerate(test_paths[:3]):\n",
    "        label = \"anomaly\" if test_labels[i] == 1 else \"normal\"\n",
    "        print(f\"  {i+1}. {path} -> {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b7813",
   "metadata": {},
   "source": [
    "# Feature Extraction - Training Data\n",
    "\n",
    "Extract features from training audio files using the EAT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "259a3aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sey87151/EAT_Clean/.venv/lib64/python3.9/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/home/sey87151/EAT_Clean/.venv/lib64/python3.9/site-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 10/35 -> (32, 768)\n",
      "[train] 20/35 -> (32, 768)\n",
      "[train] 20/35 -> (32, 768)\n",
      "[train] 30/35 -> (32, 768)\n",
      "[train] 30/35 -> (32, 768)\n",
      "[train] 35/35 -> (12, 768)\n",
      "Training features: (1100, 768)\n",
      "[train] 35/35 -> (12, 768)\n",
      "Training features: (1100, 768)\n"
     ]
    }
   ],
   "source": [
    "# 2) Load audio and extract features\n",
    "feat = EATFeatureExtractor(model_id=args.model_id, sr=args.sr,\n",
    "                           target_length=args.target_length, pool_mode=args.pool_mode)\n",
    "\n",
    "# Train features\n",
    "print(\"Extracting training features...\")\n",
    "wavs_tr = []\n",
    "for p in train_paths:\n",
    "    try:\n",
    "        wav, _ = torchaudio.load(p)\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        wavs_tr.append(wav.squeeze().numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {p}: {e}\")\n",
    "        continue\n",
    "\n",
    "if len(wavs_tr) > args.max_train:\n",
    "    idx = np.random.choice(len(wavs_tr), size=args.max_train, replace=False)\n",
    "    wavs_tr = [wavs_tr[i] for i in idx]\n",
    "    print(f\"Randomly selected {len(wavs_tr)} training samples from {len(train_paths)} total\")\n",
    "\n",
    "feats_tr = []\n",
    "tot = math.ceil(len(wavs_tr) / args.batch_size)\n",
    "for bi, batch in enumerate(chunked(wavs_tr, args.batch_size), 1):\n",
    "    cls = feat.encode_batch(batch)\n",
    "    feats_tr.append(cls)\n",
    "    if bi % 10 == 0 or bi == tot:\n",
    "        print(f\"[train] {bi}/{tot} -> {cls.shape}\")\n",
    "\n",
    "X_train = np.vstack(feats_tr) if feats_tr else np.zeros((0, 768), dtype=np.float32)\n",
    "print(f\"Training features: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385056f",
   "metadata": {},
   "source": [
    "# Feature Extraction - Test Data\n",
    "\n",
    "Extract features from test audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ec37faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features...\n",
      "[test] 7/7 -> (8, 768)\n",
      "Test features: (200, 768)\n",
      "\n",
      "Feature extraction summary:\n",
      "  Training samples: 1100\n",
      "  Test samples: 200\n",
      "  Feature dimensions: 768\n",
      "  Normal test samples: 100\n",
      "  Anomalous test samples: 100\n",
      "[test] 7/7 -> (8, 768)\n",
      "Test features: (200, 768)\n",
      "\n",
      "Feature extraction summary:\n",
      "  Training samples: 1100\n",
      "  Test samples: 200\n",
      "  Feature dimensions: 768\n",
      "  Normal test samples: 100\n",
      "  Anomalous test samples: 100\n"
     ]
    }
   ],
   "source": [
    "# Test features\n",
    "print(\"Extracting test features...\")\n",
    "wavs_te = []\n",
    "for p in test_paths:\n",
    "    try:\n",
    "        wav, _ = torchaudio.load(p)\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        wavs_te.append(wav.squeeze().numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {p}: {e}\")\n",
    "        continue\n",
    "\n",
    "feats_te = []\n",
    "tot_te = math.ceil(len(wavs_te) / args.batch_size)\n",
    "for bi, batch in enumerate(chunked(wavs_te, args.batch_size), 1):\n",
    "    cls = feat.encode_batch(batch)\n",
    "    feats_te.append(cls)\n",
    "    if bi % 10 == 0 or bi == tot_te:\n",
    "        print(f\"[test] {bi}/{tot_te} -> {cls.shape}\")\n",
    "\n",
    "X_test = np.vstack(feats_te) if feats_te else np.zeros((0, 768), dtype=np.float32)\n",
    "print(f\"Test features: {X_test.shape}\")\n",
    "\n",
    "# Verify feature dimensions match expectations\n",
    "print(f\"\\nFeature extraction summary:\")\n",
    "print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test.shape[0]}\")\n",
    "print(f\"  Feature dimensions: {X_train.shape[1] if len(X_train) > 0 else 'N/A'}\")\n",
    "print(f\"  Normal test samples: {n_test_normal}\")\n",
    "print(f\"  Anomalous test samples: {n_test_anomaly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c12f5",
   "metadata": {},
   "source": [
    "# Feature Processing and Preprocessing\n",
    "\n",
    "Apply normalization, standardization, and dimensionality reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea63b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE PROCESSING ===\n",
      "Standardization applied - Training mean: -0.000000, std: 1.000000\n",
      "Standardization applied - Test mean: -0.003322, std: 1.029913\n"
     ]
    }
   ],
   "source": [
    "# 3) Feature processing\n",
    "print(\"\\n=== FEATURE PROCESSING ===\")\n",
    "\n",
    "# Apply L2 normalization if requested\n",
    "if args.use_l2_norm:\n",
    "    print(\"Applying L2 normalization...\")\n",
    "    X_train = X_train / (np.linalg.norm(X_train, axis=1, keepdims=True) + 1e-6)\n",
    "    X_test = X_test / (np.linalg.norm(X_test, axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Standardization applied - Training mean: {X_train_std.mean():.6f}, std: {X_train_std.std():.6f}\")\n",
    "print(f\"Standardization applied - Test mean: {X_test_std.mean():.6f}, std: {X_test_std.std():.6f}\")\n",
    "\n",
    "# # PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=0.95, random_state=args.seed)\n",
    "# X_train_pca = pca.fit_transform(X_train_std)\n",
    "# X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# print(f\"After PCA: {X_train_pca.shape[1]} dimensions (explained variance: {pca.explained_variance_ratio_.sum():.3f})\")\n",
    "# print(f\"Original dimensions: {X_train_std.shape[1]} -> Reduced to: {X_train_pca.shape[1]}\")\n",
    "# print(f\"Variance explained by top 5 components: {pca.explained_variance_ratio_[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0086a",
   "metadata": {},
   "source": [
    "# Clustering Analysis and Optimal K Selection\n",
    "\n",
    "Find the optimal number of clusters using silhouette analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8aebb4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLUSTERING ===\n",
      "Testing K values from 8 to 60...\n",
      "K=8: silhouette=0.1435\n",
      "K=8: silhouette=0.1435\n",
      "K=12: silhouette=0.1325\n",
      "K=12: silhouette=0.1325\n",
      "K=16: silhouette=0.1259\n",
      "K=16: silhouette=0.1259\n",
      "K=20: silhouette=0.1286\n",
      "K=20: silhouette=0.1286\n",
      "K=24: silhouette=0.1227\n",
      "K=24: silhouette=0.1227\n",
      "K=28: silhouette=0.1288\n",
      "K=28: silhouette=0.1288\n",
      "K=32: silhouette=0.1295\n",
      "K=32: silhouette=0.1295\n",
      "K=36: silhouette=0.1320\n",
      "K=36: silhouette=0.1320\n",
      "K=40: silhouette=0.1394\n",
      "K=40: silhouette=0.1394\n",
      "K=44: silhouette=0.1397\n",
      "K=44: silhouette=0.1397\n",
      "K=48: silhouette=0.1487\n",
      "K=48: silhouette=0.1487\n",
      "K=52: silhouette=0.1469\n",
      "K=52: silhouette=0.1469\n",
      "K=56: silhouette=0.1517\n",
      "K=56: silhouette=0.1517\n",
      "K=60: silhouette=0.1468\n",
      "\n",
      "Optimal K: 56 (silhouette: 0.1517)\n",
      "K=60: silhouette=0.1468\n",
      "\n",
      "Optimal K: 56 (silhouette: 0.1517)\n",
      "Final KMeans model trained with 56 clusters\n",
      "Cluster sizes: [16 34 24 17  7 42 33 16  6 29 15  6 23 18 20 39  6 13  6 18 34 13 21 16\n",
      " 20 24  6 29 25 13 30 21 20 25 13  7 37 33 19 18 27 21 12 12 25 16 29 24\n",
      "  5 13  6 12 22 25 27 12]\n",
      "Cluster centers shape: (56, 768)\n",
      "Final KMeans model trained with 56 clusters\n",
      "Cluster sizes: [16 34 24 17  7 42 33 16  6 29 15  6 23 18 20 39  6 13  6 18 34 13 21 16\n",
      " 20 24  6 29 25 13 30 21 20 25 13  7 37 33 19 18 27 21 12 12 25 16 29 24\n",
      "  5 13  6 12 22 25 27 12]\n",
      "Cluster centers shape: (56, 768)\n"
     ]
    }
   ],
   "source": [
    "# 4) Find optimal number of clusters\n",
    "print(\"\\n=== CLUSTERING ===\")\n",
    "\n",
    "K_range = range(8, min(64, len(X_train)//10), 4)\n",
    "silhouette_scores = []\n",
    "\n",
    "print(f\"Testing K values from {min(K_range)} to {max(K_range)}...\")\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_test = KMeans(n_clusters=k, random_state=args.seed, n_init=10)\n",
    "    labels = kmeans_test.fit_predict(X_train)\n",
    "    \n",
    "    if len(np.unique(labels)) > 1:\n",
    "        sil_score = silhouette_score(X_train, labels)\n",
    "        silhouette_scores.append(sil_score)\n",
    "    else:\n",
    "        silhouette_scores.append(-1)\n",
    "    \n",
    "    print(f\"K={k}: silhouette={silhouette_scores[-1]:.4f}\")\n",
    "\n",
    "# Choose best K\n",
    "best_idx = np.argmax(silhouette_scores)\n",
    "optimal_k = list(K_range)[best_idx]\n",
    "best_sil = silhouette_scores[best_idx]\n",
    "\n",
    "print(f\"\\nOptimal K: {optimal_k} (silhouette: {best_sil:.4f})\")\n",
    "\n",
    "# Train final model\n",
    "km = KMeans(n_clusters=optimal_k, random_state=args.seed, n_init=10)\n",
    "km.fit(X_train)\n",
    "\n",
    "print(f\"Final KMeans model trained with {optimal_k} clusters\")\n",
    "print(f\"Cluster sizes: {np.bincount(km.labels_)}\")\n",
    "print(f\"Cluster centers shape: {km.cluster_centers_.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0d680",
   "metadata": {},
   "source": [
    "# Anomaly Scoring with Mahalanobis Distance\n",
    "\n",
    "Implement per-cluster Mahalanobis distance for anomaly scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97928534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANOMALY SCORING (Mahalanobis) ===\n",
      "Computing covariance matrices for 56 clusters...\n",
      "  Cluster 0: 16 samples\n",
      "  Cluster 1: 34 samples\n",
      "  Cluster 2: 24 samples\n",
      "  Cluster 3: 17 samples\n",
      "  Cluster 4: 7 samples\n",
      "  Cluster 5: 42 samples\n",
      "  Cluster 6: 33 samples\n",
      "  Cluster 7: 16 samples\n",
      "  Cluster 8: 6 samples\n",
      "  Cluster 9: 29 samples\n",
      "  Cluster 10: 15 samples\n",
      "  Cluster 11: 6 samples\n",
      "  Cluster 12: 23 samples\n",
      "  Cluster 13: 18 samples\n",
      "  Cluster 14: 20 samples\n",
      "  Cluster 15: 39 samples\n",
      "  Cluster 16: 6 samples\n",
      "  Cluster 17: 13 samples\n",
      "  Cluster 18: 6 samples\n",
      "  Cluster 19: 18 samples\n",
      "  Cluster 20: 34 samples\n",
      "  Cluster 21: 13 samples\n",
      "  Cluster 22: 21 samples\n",
      "  Cluster 23: 16 samples\n",
      "  Cluster 24: 20 samples\n",
      "  Cluster 25: 24 samples\n",
      "  Cluster 26: 6 samples\n",
      "  Cluster 27: 29 samples\n",
      "  Cluster 28: 25 samples\n",
      "  Cluster 29: 13 samples\n",
      "  Cluster 30: 30 samples\n",
      "  Cluster 31: 21 samples\n",
      "  Cluster 32: 20 samples\n",
      "  Cluster 33: 25 samples\n",
      "  Cluster 34: 13 samples\n",
      "  Cluster 35: 7 samples\n",
      "  Cluster 36: 37 samples\n",
      "  Cluster 37: 33 samples\n",
      "  Cluster 38: 19 samples\n",
      "  Cluster 39: 18 samples\n",
      "  Cluster 40: 27 samples\n",
      "  Cluster 20: 34 samples\n",
      "  Cluster 21: 13 samples\n",
      "  Cluster 22: 21 samples\n",
      "  Cluster 23: 16 samples\n",
      "  Cluster 24: 20 samples\n",
      "  Cluster 25: 24 samples\n",
      "  Cluster 26: 6 samples\n",
      "  Cluster 27: 29 samples\n",
      "  Cluster 28: 25 samples\n",
      "  Cluster 29: 13 samples\n",
      "  Cluster 30: 30 samples\n",
      "  Cluster 31: 21 samples\n",
      "  Cluster 32: 20 samples\n",
      "  Cluster 33: 25 samples\n",
      "  Cluster 34: 13 samples\n",
      "  Cluster 35: 7 samples\n",
      "  Cluster 36: 37 samples\n",
      "  Cluster 37: 33 samples\n",
      "  Cluster 38: 19 samples\n",
      "  Cluster 39: 18 samples\n",
      "  Cluster 40: 27 samples\n",
      "  Cluster 41: 21 samples\n",
      "  Cluster 42: 12 samples\n",
      "  Cluster 43: 12 samples\n",
      "  Cluster 44: 25 samples\n",
      "  Cluster 45: 16 samples\n",
      "  Cluster 46: 29 samples\n",
      "  Cluster 47: 24 samples\n",
      "  Cluster 48: 5 samples\n",
      "  Cluster 49: 13 samples\n",
      "  Cluster 50: 6 samples\n",
      "  Cluster 51: 12 samples\n",
      "  Cluster 52: 22 samples\n",
      "  Cluster 53: 25 samples\n",
      "  Cluster 54: 27 samples\n",
      "  Cluster 55: 12 samples\n",
      "Computing anomaly scores for 200 test samples...\n",
      "  Cluster 41: 21 samples\n",
      "  Cluster 42: 12 samples\n",
      "  Cluster 43: 12 samples\n",
      "  Cluster 44: 25 samples\n",
      "  Cluster 45: 16 samples\n",
      "  Cluster 46: 29 samples\n",
      "  Cluster 47: 24 samples\n",
      "  Cluster 48: 5 samples\n",
      "  Cluster 49: 13 samples\n",
      "  Cluster 50: 6 samples\n",
      "  Cluster 51: 12 samples\n",
      "  Cluster 52: 22 samples\n",
      "  Cluster 53: 25 samples\n",
      "  Cluster 54: 27 samples\n",
      "  Cluster 55: 12 samples\n",
      "Computing anomaly scores for 200 test samples...\n",
      "Anomaly scores computed:\n",
      "  Min score: 4.7304\n",
      "  Max score: 11.3713\n",
      "  Mean score: 7.2718\n",
      "  Std score: 1.3115\n",
      "Anomaly scores computed:\n",
      "  Min score: 4.7304\n",
      "  Max score: 11.3713\n",
      "  Mean score: 7.2718\n",
      "  Std score: 1.3115\n"
     ]
    }
   ],
   "source": [
    "# 5) Score test data (Per-cluster Mahalanobis distance instead of Euclidean)\n",
    "print(\"\\n=== ANOMALY SCORING (Mahalanobis) ===\")\n",
    "\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "\n",
    "mus = km.cluster_centers_\n",
    "labels_train = km.predict(X_train)\n",
    "\n",
    "covs = []\n",
    "cho_info = []\n",
    "lam = 1e-3  # ridge for numerical stability\n",
    "feat_dim = X_train.shape[1]\n",
    "\n",
    "print(f\"Computing covariance matrices for {optimal_k} clusters...\")\n",
    "\n",
    "for k in range(optimal_k):\n",
    "    Xk = X_train[labels_train == k]\n",
    "    print(f\"  Cluster {k}: {len(Xk)} samples\")\n",
    "    \n",
    "    # if len(Xk) < feat_dim + 2:\n",
    "    #     # Fallback: isotropic covariance if too few points\n",
    "    #     if Xk.shape[0] > 1:\n",
    "    #         Sk = np.cov(Xk.T)\n",
    "    #     else:\n",
    "    #         Sk = np.eye(feat_dim)\n",
    "    #     print(f\"    Using fallback covariance (too few samples)\")\n",
    "    # else:\n",
    "    Sk = np.cov(Xk.T)\n",
    "    \n",
    "    # Regularize\n",
    "    Sk = Sk + lam * np.eye(Sk.shape[0])\n",
    "    try:\n",
    "        c, lower = cho_factor(Sk, overwrite_a=False, check_finite=False)\n",
    "    except Exception as e:\n",
    "        # In rare singular cases, bump ridge and retry once\n",
    "        print(f\"    Cholesky failed, increasing regularization\")\n",
    "        Sk = Sk + 10 * lam * np.eye(Sk.shape[0])\n",
    "        c, lower = cho_factor(Sk, overwrite_a=False, check_finite=False)\n",
    "    \n",
    "    covs.append(Sk)\n",
    "    cho_info.append((c, lower))\n",
    "\n",
    "def maha_min(X, mus, cho_info):\n",
    "    \"\"\"Compute minimum Mahalanobis distance across all clusters\"\"\"\n",
    "    dists = []\n",
    "    for x in X:\n",
    "        ds = []\n",
    "        for mu, (c, lower) in zip(mus, cho_info):\n",
    "            r = x - mu\n",
    "            q = cho_solve((c, lower), r, check_finite=False)\n",
    "            ds.append(np.sqrt(np.dot(r, q)))\n",
    "        dists.append(min(ds))\n",
    "    return np.asarray(dists)\n",
    "\n",
    "print(f\"Computing anomaly scores for {len(X_test_pca)} test samples...\")\n",
    "scores = maha_min(X_test, mus, cho_info)\n",
    "\n",
    "print(f\"Anomaly scores computed:\")\n",
    "print(f\"  Min score: {scores.min():.4f}\")\n",
    "print(f\"  Max score: {scores.max():.4f}\")\n",
    "print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "print(f\"  Std score: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8093ba",
   "metadata": {},
   "source": [
    "# Performance Evaluation and Metrics\n",
    "\n",
    "Evaluate the anomaly detection performance using various metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36706f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION ===\n",
      "AUC: 0.6242\n",
      "pAUC (FPR ≤ 0.1): 0.2340\n",
      "\n",
      "Score distribution analysis:\n",
      "  Normal samples - Mean: 6.9157, Std: 1.0213\n",
      "  Anomaly samples - Mean: 7.6279, Std: 1.4640\n",
      "  Separation (anomaly_mean - normal_mean): 0.7122\n",
      "\n",
      "Optimal threshold analysis:\n",
      "  Optimal threshold: 5.4012\n",
      "  F1 score at optimal threshold: 0.6803\n",
      "  Accuracy at optimal threshold: 0.5300\n",
      "  Confusion matrix:\n",
      " [[  6  94]\n",
      " [  0 100]]\n"
     ]
    }
   ],
   "source": [
    "# 6) Evaluate performance\n",
    "print(\"\\n=== EVALUATION ===\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, scores)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "# pAUC (partial AUC for FPR <= 0.1)\n",
    "max_fpr = 0.1\n",
    "fpr_partial = fpr[fpr <= max_fpr]\n",
    "tpr_partial = tpr[fpr <= max_fpr]\n",
    "if len(fpr_partial) > 1:\n",
    "    pauc = auc(fpr_partial, tpr_partial) / max_fpr\n",
    "else:\n",
    "    pauc = 0.0\n",
    "\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "print(f\"pAUC (FPR ≤ 0.1): {pauc:.4f}\")\n",
    "\n",
    "# Initialize results dictionary for metrics\n",
    "results = {\n",
    "    \"machine\": args.machine,\n",
    "    \"auc\": float(auc_score),\n",
    "    \"pauc\": float(pauc),\n",
    "    \"optimal_k\": int(optimal_k),\n",
    "    \"silhouette_score\": float(best_sil),\n",
    "    \"n_features\": int(X_train_pca.shape[1]),\n",
    "    \"explained_variance\": float(pca.explained_variance_ratio_.sum()),\n",
    "    \"n_train\": len(X_train_pca),\n",
    "    \"n_test\": len(X_test_pca)\n",
    "}\n",
    "\n",
    "# Score distribution analysis\n",
    "normal_scores = scores[test_labels == 0]\n",
    "anomaly_scores = scores[test_labels == 1]\n",
    "\n",
    "print(f\"\\nScore distribution analysis:\")\n",
    "print(f\"  Normal samples - Mean: {normal_scores.mean():.4f}, Std: {normal_scores.std():.4f}\")\n",
    "print(f\"  Anomaly samples - Mean: {anomaly_scores.mean():.4f}, Std: {anomaly_scores.std():.4f}\")\n",
    "print(f\"  Separation (anomaly_mean - normal_mean): {anomaly_scores.mean() - normal_scores.mean():.4f}\")\n",
    "\n",
    "# Find optimal threshold using F1 score\n",
    "precision, recall, pr_thresholds = precision_recall_curve(test_labels, scores)\n",
    "f1_scores = []\n",
    "threshold_range = np.linspace(scores.min(), scores.max(), 100)\n",
    "\n",
    "for thresh in threshold_range:\n",
    "    y_pred = (scores >= thresh).astype(int)\n",
    "    if len(np.unique(y_pred)) > 1:\n",
    "        f1 = f1_score(test_labels, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    else:\n",
    "        f1_scores.append(0)\n",
    "\n",
    "optimal_thresh_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = threshold_range[optimal_thresh_idx]\n",
    "optimal_f1 = f1_scores[optimal_thresh_idx]\n",
    "\n",
    "y_pred_optimal = (scores >= optimal_threshold).astype(int)\n",
    "cm = confusion_matrix(test_labels, y_pred_optimal)\n",
    "\n",
    "print(f\"\\nOptimal threshold analysis:\")\n",
    "print(f\"  Optimal threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"  F1 score at optimal threshold: {optimal_f1:.4f}\")\n",
    "print(f\"  Accuracy at optimal threshold: {accuracy_score(test_labels, y_pred_optimal):.4f}\")\n",
    "print(f\"  Confusion matrix:\")\n",
    "print(f\" {cm}\")\n",
    "\n",
    "# Update results with additional metrics\n",
    "additional_results = {\n",
    "    \"optimal_threshold\": float(optimal_threshold),\n",
    "    \"optimal_f1\": float(optimal_f1),\n",
    "    \"accuracy_at_optimal\": float(accuracy_score(test_labels, y_pred_optimal)),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "    \"normal_score_mean\": float(np.mean(normal_scores)),\n",
    "    \"normal_score_std\": float(np.std(normal_scores)),\n",
    "    \"anomaly_score_mean\": float(np.mean(anomaly_scores)),\n",
    "    \"anomaly_score_std\": float(np.std(anomaly_scores)),\n",
    "    \"n_test_normal\": int(np.sum(test_labels == 0)),\n",
    "    \"n_test_anomaly\": int(np.sum(test_labels == 1))\n",
    "}\n",
    "results.update(additional_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f6442",
   "metadata": {},
   "source": [
    "# Visualization and Plotting\n",
    "\n",
    "Generate comprehensive plots for analysis and reporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36c2158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GENERATING PLOTS ===\n"
     ]
    }
   ],
   "source": [
    "# 7) Generate comprehensive plots\n",
    "print(\"\\n=== GENERATING PLOTS ===\")\n",
    "\n",
    "results_dir = Path(f\"./results_{args.machine}\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "plots_dir = results_dir / \"plots\"\n",
    "plots_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c11f4",
   "metadata": {},
   "source": [
    "# Plot 1: ROC Curve with AUC and pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b5d8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC curve plot saved\n"
     ]
    }
   ],
   "source": [
    "# Plot 1: ROC Curve with AUC and pAUC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "\n",
    "# Highlight pAUC region\n",
    "fpr_pauc = fpr[fpr <= max_fpr]\n",
    "tpr_pauc = tpr[fpr <= max_fpr]\n",
    "plt.fill_between(fpr_pauc, 0, tpr_pauc, alpha=0.3, color='red', \n",
    "                 label=f'pAUC ≤ {max_fpr} (pAUC = {pauc:.4f})')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title(f'ROC Curve - {args.machine.capitalize()} Anomaly Detection', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add performance text box\n",
    "textstr = f'Clusters: {optimal_k}\\\\nSilhouette: {best_sil:.3f}\\\\nFeatures: {X_train_pca.shape[1]}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.65, 0.15, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"roc_curve.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"ROC curve plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31913b57",
   "metadata": {},
   "source": [
    "# Plot 2: Score Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da2f6128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score distribution plot saved\n"
     ]
    }
   ],
   "source": [
    "# Plot 2: Score Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot 1: Histogram of scores by class\n",
    "plt.subplot(1, 2, 1)\n",
    "normal_scores = scores[test_labels == 0]\n",
    "anomaly_scores = scores[test_labels == 1]\n",
    "\n",
    "plt.hist(normal_scores, bins=30, alpha=0.7, label=f'Normal (n={len(normal_scores)})', \n",
    "         color='blue', density=True)\n",
    "plt.hist(anomaly_scores, bins=30, alpha=0.7, label=f'Anomaly (n={len(anomaly_scores)})', \n",
    "         color='red', density=True)\n",
    "plt.xlabel('Anomaly Score (Distance to Nearest Cluster)', fontsize=11)\n",
    "plt.ylabel('Density', fontsize=11)\n",
    "plt.title('Score Distribution by Class', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Box plot\n",
    "plt.subplot(1, 2, 2)\n",
    "data_to_plot = [normal_scores, anomaly_scores]\n",
    "labels_box = ['Normal', 'Anomaly']\n",
    "box_plot = plt.boxplot(data_to_plot, tick_labels=labels_box, patch_artist=True)\n",
    "box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "box_plot['boxes'][1].set_facecolor('lightcoral')\n",
    "plt.ylabel('Anomaly Score', fontsize=11)\n",
    "plt.title('Score Distribution (Box Plot)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"score_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Score distribution plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9592fd",
   "metadata": {},
   "source": [
    "# Plot 3: Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bae26511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold analysis plot saved\n"
     ]
    }
   ],
   "source": [
    "# Plot 3: Threshold Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Precision-Recall curve\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR Curve')\n",
    "plt.xlabel('Recall', fontsize=11)\n",
    "plt.ylabel('Precision', fontsize=11)\n",
    "plt.title('Precision-Recall Curve', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: F1 vs Threshold\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(threshold_range, f1_scores, linewidth=2, color='green')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', \n",
    "            label=f'Optimal Threshold = {optimal_threshold:.3f}')\n",
    "plt.xlabel('Threshold', fontsize=11)\n",
    "plt.ylabel('F1 Score', fontsize=11)\n",
    "plt.title(f'F1 Score vs Threshold (Max F1 = {optimal_f1:.3f})', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: TPR and FPR vs Threshold\n",
    "plt.subplot(2, 2, 3)\n",
    "if len(thresholds) > 1:\n",
    "    plt.plot(thresholds[1:], tpr[1:], linewidth=2, label='True Positive Rate', color='blue')\n",
    "    plt.plot(thresholds[1:], fpr[1:], linewidth=2, label='False Positive Rate', color='red')\n",
    "    plt.axvline(optimal_threshold, color='green', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Threshold', fontsize=11)\n",
    "plt.ylabel('Rate', fontsize=11)\n",
    "plt.title('TPR and FPR vs Threshold', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 4: Performance metrics summary\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix\\\\n(Optimal Threshold)', fontsize=12)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Normal', 'Anomaly'])\n",
    "plt.yticks(tick_marks, ['Normal', 'Anomaly'])\n",
    "\n",
    "# Add text annotations\n",
    "thresh_cm = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh_cm else \"black\")\n",
    "\n",
    "plt.ylabel('True Label', fontsize=11)\n",
    "plt.xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / \"threshold_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Threshold analysis plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d22ce",
   "metadata": {},
   "source": [
    "# Plot 4: Clustering Visualization (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be6ffee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing t-SNE for visualization...\n",
      "Clustering visualization (t-SNE) plot saved\n",
      "Clustering visualization (t-SNE) plot saved\n"
     ]
    }
   ],
   "source": [
    "# Plot 4: Clustering Visualization (if enough data points)\n",
    "if len(X_train) > 50:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    try:\n",
    "        from sklearn.manifold import TSNE\n",
    "        # Combine train and test for consistent visualization\n",
    "        X_combined = np.vstack([X_train, X_test])\n",
    "        \n",
    "        print(\"Computing t-SNE for visualization...\")\n",
    "        tsne = TSNE(n_components=2, random_state=args.seed, perplexity=min(30, len(X_combined)//4))\n",
    "        X_2d = tsne.fit_transform(X_combined)\n",
    "        \n",
    "        # Separate back into train/test\n",
    "        X_train_2d = X_2d[:len(X_train)]\n",
    "        X_test_2d = X_2d[len(X_train):]\n",
    "\n",
    "        # Plot training data points\n",
    "        plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c='lightblue', alpha=0.6, \n",
    "                   s=20, label=f'Training (Normal, n={len(X_train_2d)})')\n",
    "        \n",
    "        # Plot test data points\n",
    "        normal_mask = test_labels == 0\n",
    "        anomaly_mask = test_labels == 1\n",
    "        \n",
    "        plt.scatter(X_test_2d[normal_mask, 0], X_test_2d[normal_mask, 1], \n",
    "                   c='blue', alpha=0.8, s=30, label=f'Test Normal (n={np.sum(normal_mask)})')\n",
    "        plt.scatter(X_test_2d[anomaly_mask, 0], X_test_2d[anomaly_mask, 1], \n",
    "                   c='red', alpha=0.8, s=30, label=f'Test Anomaly (n={np.sum(anomaly_mask)})')\n",
    "        \n",
    "        plt.xlabel('t-SNE Component 1', fontsize=12)\n",
    "        plt.ylabel('t-SNE Component 2', fontsize=12)\n",
    "        plt.title(f'Clustering Visualization (t-SNE) - {args.machine.capitalize()}', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / \"clustering_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Clustering visualization (t-SNE) plot saved\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate t-SNE visualization: {e}\")\n",
    "else:\n",
    "    print(\"Not enough data points for t-SNE visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075090fb",
   "metadata": {},
   "source": [
    "# Results Summary and Export\n",
    "\n",
    "Final summary and save results to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45773b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL SUMMARY ===\n",
      "Plots saved to results_bearing/plots\n",
      "  - ROC curve with pAUC highlighting\n",
      "  - Score distribution analysis\n",
      "  - Threshold optimization analysis\n",
      "  - Clustering visualization (t-SNE)\n",
      "\n",
      "Cluster statistics:\n",
      "  Number of clusters: 56\n",
      "  Silhouette score: 0.1517\n",
      "  Feature dimensions: 768\n",
      "  Training samples: 1100\n",
      "  Test samples: 200\n",
      "\n",
      "Performance Summary:\n",
      "  AUC: 0.6242\n",
      "  pAUC: 0.2340\n",
      "  Optimal F1: 0.6803\n",
      "  Accuracy: 0.5300\n",
      "\n",
      "Results saved to results_bearing\n",
      "  - results_with_plots.json: Complete metrics\n",
      "  - test_scores.npy: Anomaly scores\n",
      "  - test_labels.npy: True labels\n",
      "\n",
      "✅ Anomaly detection pipeline completed successfully!\n",
      "\n",
      "Results saved to results_bearing\n",
      "  - results_with_plots.json: Complete metrics\n",
      "  - test_scores.npy: Anomaly scores\n",
      "  - test_labels.npy: True labels\n",
      "\n",
      "✅ Anomaly detection pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Final results summary and export\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Plots saved to {plots_dir}\")\n",
    "print(f\"  - ROC curve with pAUC highlighting\")\n",
    "print(f\"  - Score distribution analysis\")\n",
    "print(f\"  - Threshold optimization analysis\")\n",
    "if len(X_train) > 50:\n",
    "    print(f\"  - Clustering visualization (t-SNE)\")\n",
    "\n",
    "# Feature and clustering stats\n",
    "print(f\"\\nCluster statistics:\")\n",
    "print(f\"  Number of clusters: {optimal_k}\")\n",
    "print(f\"  Silhouette score: {best_sil:.4f}\")\n",
    "print(f\"  Feature dimensions: {X_train.shape[1]}\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Test samples: {len(X_test)}\")\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"  AUC: {auc_score:.4f}\")\n",
    "print(f\"  pAUC: {pauc:.4f}\")\n",
    "print(f\"  Optimal F1: {optimal_f1:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy_score(test_labels, y_pred_optimal):.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "with open(results_dir / \"results_with_plots.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "np.save(results_dir / \"test_scores.npy\", scores)\n",
    "np.save(results_dir / \"test_labels.npy\", test_labels)\n",
    "\n",
    "print(f\"\\nResults saved to {results_dir}\")\n",
    "print(f\"  - results_with_plots.json: Complete metrics\")\n",
    "print(f\"  - test_scores.npy: Anomaly scores\")\n",
    "print(f\"  - test_labels.npy: True labels\")\n",
    "print(\"\\n✅ Anomaly detection pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc22c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, wavs: List[np.ndarray], labels: np.ndarray, sr: int, target_len: Optional[int]):\n",
    "        assert len(wavs) == len(labels)\n",
    "        self.wavs = wavs\n",
    "        self.labels = labels.astype(np.int64)\n",
    "        self.sr = sr\n",
    "        self.target_len = target_len\n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "    def __getitem__(self, idx: int):\n",
    "        w = self.wavs[idx]; y = int(self.labels[idx])\n",
    "        w_t = torch.tensor(w, dtype=torch.float32)\n",
    "        if w_t.ndim!=1:\n",
    "            w_t = w_t.view(-1)\n",
    "        w_t = w_t - w_t.mean()\n",
    "        fb = torchaudio.compliance.kaldi.fbank(\n",
    "            w_t.unsqueeze(0), htk_compat=True, sample_frequency=self.sr,\n",
    "            use_energy=False, window_type=\"hanning\", num_mel_bins=128,\n",
    "            dither=0.0, frame_shift=10,\n",
    "        )\n",
    "        T_true = fb.size(0)\n",
    "        if self.target_len is not None:\n",
    "            if T_true < self.target_len:\n",
    "                fb = F.pad(fb, (0,0,0,self.target_len - T_true))\n",
    "            elif T_true > self.target_len:\n",
    "                fb = fb[: self.target_len, :]\n",
    "        fb = (fb + 4.288) / 4.469\n",
    "        L = min(T_true, self.target_len or T_true)\n",
    "        return fb.unsqueeze(0), y, L\n",
    "\n",
    "def collate_fb(items):\n",
    "    fbs, ys, lens = zip(*items)\n",
    "    x = torch.stack(fbs, dim=0)\n",
    "    y = torch.tensor(ys, dtype=torch.long)\n",
    "    lengths = torch.tensor(lens, dtype=torch.long)\n",
    "    return x, y, lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nb)",
   "language": "python",
   "name": "nb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
